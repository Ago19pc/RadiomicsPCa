{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e41a722",
   "metadata": {},
   "source": [
    "# Polyjuice Potion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b438e84c",
   "metadata": {},
   "source": [
    "You might be asking what is this...\n",
    "\n",
    "Just a mix and mash of ADC, T2W and so on\n",
    "\n",
    "TODO: Definire classe 1 e 2 per esempio classe 1: ISUP 2,3 mentre classe 2: ISUP 3,4.\n",
    "\n",
    "Una classe puo avere 1 o piu valori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06463c43",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9c41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a7227f",
   "metadata": {},
   "source": [
    "# Data Reader (!IMPORTANT!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3a115ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_single_string(param):\n",
    "    return isinstance(param, str)\n",
    "\n",
    "def is_list_of_strings(param):\n",
    "    return isinstance(param, (list, tuple)) and all(isinstance(item, str) for item in param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a610426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_polyjuice_getter(sequence, dataset):\n",
    "    # Filter the dataset to include only AI annotations and selected sequences and ROI lesion\n",
    "    filtered_dataset = dataset[dataset['annotator'] == 'AI']\n",
    "    filtered_dataset = filtered_dataset[filtered_dataset['sequence'] == sequence]\n",
    "    filtered_dataset = filtered_dataset[filtered_dataset['ROI'] == 'lesion']\n",
    "    filtered_dataset.drop(columns=['annotator', 'sequence', 'ROI_ID', 'ROI','img_path', 'seg_path', 'extraction_ID'], inplace=True)\n",
    "    dataset = filtered_dataset\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "700a59d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyjuice_getter(sequence, dataset):\n",
    "    polyjuice_dataset = None\n",
    "    filtered_dataset = dataset[dataset['annotator'] == 'AI']\n",
    "    filtered_dataset = filtered_dataset[filtered_dataset['ROI'] == 'lesion']\n",
    "    filtered_dataset.drop(columns=['annotator', 'ROI_ID', 'ROI','img_path', 'seg_path', 'extraction_ID'], inplace=True)\n",
    "\n",
    "    for index, s in enumerate(sequence):\n",
    "        s_dataset = filtered_dataset[filtered_dataset['sequence'] == s]\n",
    "        s_dataset = s_dataset.drop(columns=['sequence'])\n",
    "        for col in s_dataset.columns:\n",
    "            if col != 'patient_ID' and col != 'study_ID':\n",
    "                s_dataset = s_dataset.rename(columns={col : str(col + '_' + s)})\n",
    "        if index == 0:\n",
    "            polyjuice_dataset = s_dataset\n",
    "        else:\n",
    "            polyjuice_dataset = pd.merge(polyjuice_dataset, s_dataset, on=['patient_ID', 'study_ID'], how='inner')\n",
    "\n",
    "    return polyjuice_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0638c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SingleSequence = Literal['t2w', 'adc', 'hbv']\n",
    "\n",
    "\n",
    "def get_data(sequence : SingleSequence | str | list[str], isup_class1 : list[int] = [0, 1, 2], isup_class2 : list[int] = [3, 4, 5], corr_cutoff=0.9):\n",
    "    '''\n",
    "    @param squence : What sequence do you want to study. A list of multiple sequence will also work!\n",
    "    @param isup_class1 : What ISUP values do you want in the first class\n",
    "    @param isup_class2 : What ISUP values do you want in the second class\n",
    "    @param corr_cutoff : The value to cutoff high correlated features\n",
    "\n",
    "    @return pd.DataFrame : a new columns 'is_class1' is added, specofing if the row is in class1\n",
    "\n",
    "    Please read the code and the comments, especially the one at the bottom! Some unwanted columns may still be present\n",
    "    '''\n",
    "\n",
    "    is_polyjuice = None\n",
    "    if is_list_of_strings(sequence):\n",
    "        # Is a vector and not a string\n",
    "        if len(sequence) > 1:\n",
    "            # Len > 1 so we are in a polyjuice (mix)\n",
    "            is_polyjuice = True\n",
    "        else:\n",
    "            is_polyjuice = False\n",
    "    else:\n",
    "        is_polyjuice = False\n",
    "\n",
    "    labels = pd.read_csv('marksheet.csv')\n",
    "    dataset = pd.read_csv('PI-CAI_features')\n",
    "\n",
    "    new_dataset = None\n",
    "    if is_polyjuice == False:\n",
    "        new_dataset = no_polyjuice_getter(sequence, dataset)\n",
    "    else:\n",
    "        new_dataset = polyjuice_getter(sequence, dataset)\n",
    "\n",
    "\n",
    "    # The commented code below was an assumption requested in earlier version of this code, just uncomment if needed\n",
    "    # We only want Magnetic Resonace Biopsy (MRBx) labels because Systematic Biopsy (SBx) labels are not for our usecase\n",
    "    # we also remove those that have both because clicinians result might be biased\n",
    "    #labels = labels[labels['histopath_type'] == 'MRBx']\n",
    "\n",
    "    \n",
    "    labels.rename(columns={'patient_id': 'patient_ID', 'study_id': 'study_ID'}, inplace=True)\n",
    "    labels.drop(columns=['mri_date', 'histopath_type', 'center', 'lesion_ISUP', 'lesion_GS'], inplace=True)\n",
    "    \n",
    "\n",
    "    # Remove high correlated features\n",
    "    corr_matrix = new_dataset.drop(columns=['study_ID', 'patient_ID']).corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > corr_cutoff)]\n",
    "    new_dataset.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "    \n",
    "    # Drop missing values, perhaps a better way might be useful. What about KNNImputer? If so, maybe checking that we don't miss much values before imputing new ones\n",
    "    labels.dropna(inplace=True)\n",
    "    \n",
    "    # Rename Yes to 1 and No to 0 in the labels dataset\n",
    "    labels.case_csPCa = labels.case_csPCa.map(lambda x: 1 if x == 'YES' else 0)      # Is this line really useful??? Maybe we just need to drop this column\n",
    "\n",
    "    merge = pd.merge(new_dataset, labels, on=['patient_ID', 'study_ID'], how='inner')\n",
    "    merge.drop(columns=['patient_ID', 'study_ID'], inplace=True)\n",
    "\n",
    "    isup = 'case_ISUP'\n",
    "\n",
    "\n",
    "    if sum(isup_class1 + isup_class2) == 15 and len(isup_class1 + isup_class2) == 6:\n",
    "        # class1 and class2 contains all possible values (from 0 to 5)\n",
    "        merge['is_class1'] = merge[isup].map(lambda x: 1 if x in isup_class1 else 0)\n",
    "    else:\n",
    "        # class1 and class2 don't contain all possible values, so we need to drop some\n",
    "        merge = merge[merge[isup].isin(isup_class1 + isup_class2)]\n",
    "        merge['is_class1'] = merge[isup].map(lambda x: 1 if x in isup_class1 else 0)\n",
    "\n",
    "    # IMPORTANT, README\n",
    "    # Probably we need to drop case_ISUP and case_csPCa\n",
    "\n",
    "\n",
    "    return merge\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20ae40de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "276    0\n",
       "277    0\n",
       "278    1\n",
       "279    1\n",
       "280    0\n",
       "Name: is_class1, Length: 281, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edited = get_data(['t2w', 'adc'])\n",
    "\n",
    "edited['is_class1']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
